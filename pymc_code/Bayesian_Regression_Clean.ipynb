{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fe29d1-7373-413b-ac48-80d97f24066c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction to Bayesian & Frequentist Methodologies w/FAQs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b67490d-7a27-4d3e-8b8e-e9382b7a495a",
   "metadata": {},
   "source": [
    "- Bayesian methodologies assume the data is fixed and the parameters are variable - aka we are going to model this data but not be 100% sure about the coefficients.\n",
    "- Frequentist methodologies assume the data is variable and the parameters are fixed - aka we are going to assume this model is a sample and get as close as we can to the exact mean value of the coefficient.\n",
    "1. Does Bayesian provide better/different insights for econometric modeling? When is the right scenario to use that versus statsmodels?\n",
    "    - It provides more depth around your coefficients and their uncertainty/range. Bayesian models shine with smaller data where more complexity is needed.\n",
    "2. Are there times where you DONT need to bother with Bayesian analysis?\n",
    "    - It tends to be slower and more resource intensive so when you are running an MVP and want quick results, go with statsmodels\n",
    "3. Does it work better for a particular target than others? (thinking about revenue vs conversion)\n",
    "    - It does not work particularly better for a target type, but it might help us better model revenue as we can graph the proper distribution vs the linear assumption that comes with OLS. I also feel like we have a good binary system w/logistic regression in statsmodels (revenue is my answer but it's subjective)\n",
    "4. Any limitations with the number variables you use in a Bayesian model, or is it {gif}\n",
    "    - How much time do you have?\n",
    "5. Are results the same? If not, why? If not, which one is correct or more accurate?\n",
    "    - The larger the data, the larger the MCMC samples, the closer your mean of your distribution should match the coefficient of the frequentist regression. Neither are more correct or accurate.\n",
    "6. As we will be wrapping them within a script so we might not get to see the underlying function but which function did you find more intuitive to use?\n",
    "    - I'm so used to frequentist that it makes more sense, but if you get used to the bayesian way, it can be more elegant\n",
    "7. What does the PYMC output summary look like? Which of the two summaries did you find to be more useful?\n",
    "    - Once again, I'm used to the statsmodels output so I find that more intuitive, but I like the visualizations PYMC/Arviz supplies.\n",
    "8. What are the added advantages of PYMC, if any?\n",
    "    - Instead of the binary thoughts of stat sig, we can give them a distribution of values where the true value lies. PYMC over other bayesian libraries - PYMC is in python and actively kept up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a6223-1f45-4e84-97d1-ff215416447e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PYMC Bayesian Regression - Binary Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed386e0-c827-4da6-b554-8f4cd10237dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "# Optional to Standardize Variables                    #\n",
    "# ==================================================== #\n",
    "\n",
    "# pros: sampling efficiency (NUTS), numerical stability (MCMC), you can transform back to normal at the end (or not - interpret the standard deviation)\n",
    "# I saw it go from 48 seconds to 16 seconds\n",
    "# x_norm = (x - x.mean()) / x.std() # x was created above!\n",
    "x_norm = x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b58fba-dce5-4e8a-823b-497b227617d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Naming your pm.Model and opening it up in the context editor to add and change parameters - could code this up differently but not recommended\n",
    "with pm.Model() as the_model:\n",
    "    \n",
    "    # ==================================================== #\n",
    "    # Prior probabilities for the intercept & coefficients #\n",
    "    # ==================================================== #\n",
    "    \n",
    "    # priors\n",
    "    # mu - the location or center or mean of your data - if you think your coef is + then make it positive, otherwise you can make it negative\n",
    "    # sigma - the standard deviation or spread of your data - a large sd would indicate strong confidence in your prior, whereas a small sd indicates uncertainty\n",
    "    # examples: mu=2, sigma=1, strong priors; mu=1 sigma=10, weak priors; mu=0, sigma=100, uninformative priors\n",
    "    # Use priors to input domain knowledge, regularlization to avoid overfitting, and make small data more robus\n",
    "    \n",
    "    # intercept: represents the predicted value of the dependent variable when all independent variables are equal to zero\n",
    "    # mu is 0 because we do not have a prior about the intercept\n",
    "    # sigma is 10 because we have lots of uncertainty about the prior\n",
    "    # the first variable is the python name which can be used to reference the variable\n",
    "    # the second variable in quotes is PYMC variable name which is a label you'll see in your plots\n",
    "    intercept = pm.Normal('intercept',mu=0,sigma=10)\n",
    "    \n",
    "    # Betas - even if you have features that are binary, you model them all with normal distributions\n",
    "    # This is because it's the variable that is binary, not the coefficient\n",
    "    beta_var1 = pm.Normal('beta_var1',mu=0,sigma=10)\n",
    "    beta_var2 = pm.Normal('beta_var2',mu=0,sigma=10)\n",
    "    beta_var3 = pm.Normal('beta_var3',mu=0,sigma=10)\n",
    "    \n",
    "    # Another way of doing this if you have a lot of features\n",
    "    # beta = pm.Normal('beta', mu=0, sigma=10, shape=X.shape[1] - 1)\n",
    "    # logits = intercept + pm.math.dot(X.iloc[:, 1:], beta)\n",
    "        # or this...\n",
    "    # import pytensor.tensor as at\n",
    "    # july_cpm_cert_drops = pm.Model(coords={\"predictors\": columns}) # outside of the pm.Model() context\n",
    "    # beta = pm.Normal(\"beta\", 0, 10, dims=\"predictors\")\n",
    "    # beta0 = pm.Normal(\"beta0\", 0, 10)\n",
    "    # mu = beta0 + at.dot(X_train, beta)\n",
    "    \n",
    "    \n",
    "    # ==================================================== #\n",
    "    # Logistic Likelihood                                  #\n",
    "    # ==================================================== #\n",
    "    \n",
    "    # Regression Formula\n",
    "    logits = (intercept\n",
    "              + beta_var1 * x_norm['var1']\n",
    "              + beta_var2 * x_norm['var2']\n",
    "              + beta_var3 * x_norm['var3']\n",
    "             )\n",
    "    \n",
    "    # Dependent variable (Bernoulli Distribution)\n",
    "    y_obs = pm.Bernoulli('y_obs', logit_p=logits, observed=y)\n",
    "    \n",
    "    \n",
    "    # ==================================================== #\n",
    "    # MCMC NUTS Process                                    #\n",
    "    # ==================================================== #\n",
    "    \n",
    "    # Magic Inference Button\n",
    "    # 2000 samples from the posterior distribution (2000-5000 is good, closer to 100000 is great)\n",
    "    # More is better - the samples build up over time as it explores the space - only negative is time and resources\n",
    "    # Increase when you have a complex model or want precision\n",
    "    # Decrease when you don't have time or are prototyping\n",
    "    # trace = pm.sample(4000, return_inferencedata=True)\n",
    "    \n",
    "    # When to use multiple chains\n",
    "    trace = pm.sample(4000, chains=4, return_inferencedata=True)\n",
    "    # 1. Diagnostics for convergence -> they should overlap in the trace plots\n",
    "    # 2. Avoiding local minima -> The chains are exploring a posterior space and can get caught in local regions of space\n",
    "    # 3. Poor mixing happens when MCMC struggles to move across parameter space, multiple chains helps here\n",
    "    # 4. Improves effectiveness of small sample sizes, improves autocorrelation and improves quality of inferences\n",
    "    # Use for complex models, diagnositcs, uncertain priors, multi-modal posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6d5fe-467d-4dca-9119-ae61e9164647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After sampling, you can convert the coefficients back to the original scale:\n",
    "# If needed, you can back-transform them for interpretability.\n",
    "# beta_var1_original = trace['beta_var1'].mean() * x['var1'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e4ea4-89ae-4608-8dcc-3a72406b6003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "# Visualize Model Results & Diagnostics                #\n",
    "# ==================================================== #\n",
    "\n",
    "# Visualize Trace which gives us posterior distributions for the intercept and each beta coefficient\n",
    "\n",
    "# Left #\n",
    "#------#\n",
    "# Posterior distribution plots show the range of values for each coefficient which can help us understand the uncertainty around the causal effect of the variable\n",
    "# You want to see a normal distribution bell curve - shows the model converged properly; Skewed or multimodal is no good\n",
    "# Wider distributions shows more uncertainty (narrow=more certainty, but they can be too narrow...)\n",
    "\n",
    "# Right #\n",
    "#-------#\n",
    "# Trace plots: value of sampled parameter at each step of the MCMC process - look for a fuzzy catapillar\n",
    "# After the inital \"burn-in\" period, it should look noisy but stable horizontal band - meaning it converged & is exploring the posterior distribution effectively\n",
    "# It should not show any drift, it should be on the line of the mean\n",
    "# It should also show good mixing of different values\n",
    "# Sometimes you disgard the early samples that are part of that burn-in period (person does this, so ask him)\n",
    "\n",
    "# Signals #\n",
    "#---------#\n",
    "# Trace plots that are sticky or deviating off the mean\n",
    "# Trace plots with multiple chains that don't overlap\n",
    "# Trade plots that are multi-modal\n",
    "# Too wide or too narrow posterior distributions\n",
    "\n",
    "# Diagnostics #\n",
    "#-------------#\n",
    "# Gelman-Rubin Stat (R-hat) -> check if chains have converged, < 1.1 means chains have converged\n",
    "# Effective Sample Size -> How many ind samples the MCMC algorithm has drawn, if ESS is smaller than totla samples, then poor mixing\n",
    "# Check for autocorrelation of MCMC samples\n",
    "# Trace plots for multiple chains -> set chains=4 on the pm.sample function & check if the chains overlap for good convergence\n",
    "\n",
    "az.plot_trace(trace);\n",
    "# plt.show();\n",
    "# while this may not look fantastic...google what a bad one looks like and you'll see this is perfectly a-okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cb3fa-5988-400c-b42c-c60af8c08536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ff16f-7312-4cc7-9da7-eeb0ed3ca924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "# Summarize Model Results                              #\n",
    "# ==================================================== #\n",
    "# Summary of the posterior distributions\n",
    "# The 95% HDI shows where the bulk of the poterior mass lies\n",
    "az.summary(trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e8414-cbc6-4534-a889-576d04063442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Graph out model structure\n",
    "# pm.model_to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc79d5-f643-470a-8f1f-2d61abcead46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Posterior Predictive Check\n",
    "ppc = pm.sample_posterior_predictive(trace, model=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0df8fe-0a9d-4ac3-8852-bfaf0840c4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare observed data to simulated posterior data\n",
    "sns.histplot(y, color='blue', label='Observed', kde=True)\n",
    "sns.histplot(ppc.posterior_predictive.y_obs.mean(axis=0), color='orange', label='Posterior Predictive', kde=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42793e8-b58b-49ce-b9d3-07be1b351661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pair Plot (Joint Posterior Distributions)\n",
    "az.plot_pair(trace, kind=\"kde\", marginals=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c27a98-7473-4ce1-84fd-454db4520672",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rank Plot\n",
    "az.plot_rank(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bab76-71da-47a6-a9f5-5e9a803cd61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Posterior Interval Plot (HDI Plot)\n",
    "az.plot_forest(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd8210-af87-41b0-aff4-bc262e5547eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LOO (Leave One Out) Plot\n",
    "# help(az.loo)\n",
    "# loo = az.loo(trace,\n",
    "# az.plot_loo_pit(loo)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1cda7-fd2a-47cd-9ec3-a96a9745b35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_energy(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b41b07-7306-487c-99ac-9a7512ab1b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# az.plot_cdf(trace)\n",
    "az.plot_density(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db110728-7ab5-4ee8-986a-a5bfcf14d69e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# az.plot_corr(trace)\n",
    "az.plot_autocorr(trace)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "analysis_notebook",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "analysis_notebook (Local)",
   "language": "python",
   "name": "analysis_notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
